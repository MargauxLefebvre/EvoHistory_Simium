---
title: "About the dataset..."
author: "Margaux Lefebvre"
date: "`r Sys.Date()`"
output:
  github_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval = FALSE) #prevent all chunks from running
library(tidyverse)
```

# The sources

The samples are drawn from several literature sources:

* [Daron *et al.* (2021)](https://doi.org/10.1126/sciadv.abc3713) (n=499 *P. vivax*)
* [Benavente *et al* (2021)](https://doi.org/10.1038/s41467-021-23422-3) (n=125 *P. vivax*)
* [MalariaGEN project *P. vivax* Genome Variation](https://doi.org/10.12688/wellcomeopenres.17795.1) (n=295 *P. vivax*)
* [Lefebvre *et al* (2024)](https://doi.org/10.1101/2024.05.08.592893) (n=214 *P. vivax*)
* [de Oliveira *et al* (2021)](https://doi.org/10.1371/journal.pntd.0008808) (n=1 *P. vivax* and n=10 *P. simium*)
* [Ibrahim *et al* (2023)](https://doi.org/10.1016/j.lana.2022.100420) (n=11 *P. simium*)
* [Mourier *et al* (2021)](https://doi.org/10.1186/s12915-021-01139-5) (n=2 *P. vivax* and n=8 *P. simium*)

The samples from Daron *et al.* (2021), Benavente *et al* (2021), MalariaGEN project *P. vivax* Genome Variation and Lefebvre *et al* (2024) were already filtered as described in Lefebvre *et al* (2024) and in [this Github repository](https://github.com/MargauxLefebvre/LatinAmerica_vivax/tree/main/Dataset_generation#filtering-of-the-dataset).

# Produce unfiltered VCF with all samples 

## Mapping

Version: cutadapt v1.18, bwa-mem v0.7.17, samtools v1.9.

```{bash}
echo "--> Start processing: $downId" #downId is the name of the sample

#Rename the files in order to remain consistent with the rest of the script
mv ${downId}_1.fastq.gz ${downId}.R1.fastq.gz
mv ${downId}_2.fastq.gz ${downId}.R2.fastq.gz

  zcat ${downId}.R1.fastq.gz | sed -E 's/^((@|\+)'$downId'\.[^.]+)\.(1|2)/\1/' | bgzip > $downId.raw.1.fastq.gz
  zcat ${downId}.R2.fastq.gz | sed -E 's/^((@|\+)'$downId'\.[^.]+)\.(1|2)/\1/' | bgzip > $downId.raw.2.fastq.gz

# Remove adapters and preprocessed to eliminate low-quality reads. Reads shorter than 50 bp containing “N” were discarded.
  cutadapt -a AGATCGGAAGAGCACACGTCTGAA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT -q 30 -m 25 --max-n 0 -o $downId.R1.fastq.gz -p $downId.R2.fastq.gz $downId.raw.1.fastq.gz $downId.raw.2.fastq.gz

#Sequenced reads were aligned to the P. vivax reference genome PVP01
  bwa mem -t 1 P.vivax-PvP01_reference_genome.fasta $downId.R1.fastq.gz $downId.R2.fastq.gz | samtools view -F 4 -b - | samtools sort - -o $downId.mapPV.sort.bam

samtools index $downId.mapPV.sort.bam
```

## Calling

Version: GATK v3.8.0, samtools v1.9, Picard tools v2.5.0.

```{bash}
# Create Sequence Dictionary
java -jar /usr/local/picard-tools-2.5.0/picard.jar CreateSequenceDictionary R=P.vivax-PvP01_reference_genome.fasta O=P.vivax-PvP01_reference_genome.dict

# Mark the duplicated reads
java -Xss5m -jar /usr/local/picard-tools-2.5.0/picard.jar MarkDuplicates INPUT=$downId.mapPV.sort.bam OUTPUT=$downId.map.sort.dedup.bam METRICS_FILE=metrics.txt
samtools index $downId.map.sort.dedup.bam

#Add or Replace Read Groups
java -Xss5m -jar /usr/local/picard-tools-2.5.0/picard.jar AddOrReplaceReadGroups I=$downId.map.sort.dedup.bam O=$downId.map.sort.dedup.rg.bam LB=LIB-$downId PL=ILLUMINA PU=H0164ALXX140820:2:1101 SM=$downId

rm $downId.map.sort.dedup.bam $downId.map.sort.dedup.bam.bai
samtools index $downId.map.sort.dedup.rg.bam

# SplitNCigarReads
java -Xss5m -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T SplitNCigarReads -R P.vivax-PvP01_reference_genome.fasta -I $downId.map.sort.dedup.rg.bam -o $downId.map.sort.dedup.rg.rq.bam -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60 -U ALLOW_N_CIGAR_READS

rm $downId.map.sort.dedup.rg.bam $downId.map.sort.dedup.rg.bam.bai
samtools index $downId.map.sort.dedup.rg.rq.bam

# Local realignment around indels
java -Xss5m -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T RealignerTargetCreator -R P.vivax-PvP01_reference_genome.fasta -I $downId.map.sort.dedup.rg.rq.bam -o $downId.realignertargetcreator.intervals

java -Xmx8G -Djava -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T IndelRealigner -R P.vivax-PvP01_reference_genome.fasta -targetIntervals $downId.realignertargetcreator.intervals -I $downId.map.sort.dedup.rg.rq.bam -o $downId.map.sort.dedup.indelrealigner.bam
mv $downId.map.sort.dedup.indelrealigner.bam $downId.bwa.gatk.sort.bam

samtools index $downId.bwa.gatk.sort.bam

# Calling with HaplotypeCaller for ploidy 1
java -Xss5m -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T HaplotypeCaller -R P.vivax-PvP01_reference_genome.fasta -I $downId.bwa.gatk.sort.bam --genotyping_mode DISCOVERY -stand_call_conf 10 -o $downId.ploidy2.raw_variants.snp.indel.g.vcf -ERC GVCF --sample_ploidy 2
```

## Combining all the samples and keep only the nuclear genome

Version: GATK v3.8.0, bcftools v1.10.2.

```{bash}
#Merge all the samples
java -Xmx8G -Djava -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T CombineGVCFs -R P.vivax-PvP01_reference_genome.fasta --variant vcfs.ploidy2.list -o VivaxSimium_temp.ploidy2.vcf
bgzip VivaxSimium_temp.ploidy2.vcf
tabix VivaxSimium_temp.ploidy2.vcf.gz

#Keep only the variants
java -Xmx8G -Djava -jar ~/softs/GenomeAnalysisTK-3.8-0-ge9d806836/GenomeAnalysisTK.jar -T GenotypeGVCFs -R P.vivax-PvP01_reference_genome.fasta -V VivaxSimium_temp.ploidy2.vcf.gz -o  VivaxSimium_temp.raw_variants.ploidy2.vcf
bgzip VivaxSimium_temp.raw_variants.ploidy2.vcf
tabix  VivaxSimium_temp.raw_variants.ploidy2.vcf.gz

#Keep nuclear core_genome
bcftools view  VivaxSimium_temp.raw_variants.ploidy2.vcf.gz -R vivax_core_genome.bcf.txt -O z -o VivaxSimium.core.snps.ploidy2.vcf.gz
tabix VivaxSimium.core.snps.ploidy2.vcf.gz
```

# Filtering of the dataset

## Quality and depth filtering

Version: bcftools v1.10.2, vcftools v0.1.16.

First, I will focus on the VCF with ploidy = 2. With this file, I can calculate the co-infection index, essential to filter the dataset properly.
```{bash}
# Filter out a little to have only the information we need

### Keep only SNPs, regardless the number of alleles, the MAF or even the quality
vcftools --gzvcf VivaxSimium.core.snps.ploidy2.vcf.gz \
--remove-indels --non-ref-ac-any 1 \
--recode --stdout | bgzip -c > VivaxSimium_total_snp.ploidy2.vcf.gz

# See the info
VCF=VivaxSimium_total_snp.ploidy2.vcf.gz
OUT=VivaxSimium_total.ploidy2

vcftools --gzvcf $VCF --freq2 --out $OUT --max-alleles 2 &
vcftools --gzvcf $VCF --depth --out $OUT &
vcftools --gzvcf $VCF --site-mean-depth --out $OUT &
vcftools --gzvcf $VCF --site-quality --out $OUT &
vcftools --gzvcf $VCF --missing-indv --out $OUT &
vcftools --gzvcf $VCF --missing-site --out $OUT &
```

Filtering info:

* The minimum variant quality (Phred score) is 10, so we have to filter to 30.
* For the variant mean depth, we will set the minimum at 5X. The maximum will be set at 90X (= mean depth + twice the standard-deviation).
* For the individual mean depth, we will set the minimum at 5X and the maximum at 152X (= mean depth + twice the standard-deviation).
* We remove all the individuals with more than 50% of missing data: it removes 9 samples.
* Remove all the SNPs with more than 25% of missing data.
* To avoid sequencing error, we usually put the MAF at 1/number of samples : 1/453=0.00220750552

Applying filters to VCF
```{bash}
VCF_IN=VivaxSimium_total_snp.ploidy2.vcf.gz
VCF_OUT=VivaxSimium_total_snpbi_filtered.ploidy2.vcf.gz

# set filters
MAF=0.00220750552
MISS=0.5
QUAL=30
MIN_DEPTH_SNP=5
MAX_DEPTH_SNP=90
MIN_DEPTH=5
MAX_DEPTH=152

vcftools --gzvcf $VCF_IN --remove remove_miss.txt --min-alleles 2 --max-alleles 2 \
--remove-indels --maf $MAF --max-missing $MISS --minQ $QUAL \
--min-meanDP $MIN_DEPTH_SNP --max-meanDP $MAX_DEPTH_SNP \
--minDP $MIN_DEPTH --maxDP $MAX_DEPTH --recode --stdout | gzip -c > $VCF_OUT
```

What have we done here?

* `--remove remove_miss.txt` - remove all all the individuals with more than 50% of missing data
* `--min-alleles 2 --max-alleles 2` - keep only the bi-allelic SNPs
* `--remove-indels` - remove all indels (SNPs only)
* `--maf`- set minor allele frequency - here 1/number of samples
* `--max-missing` - set minimum missing data. A little counter intuitive - 0 is totally missing, 1 is none missing. Here 0.5 means we will tolerate 50% missing data.
* `--minQ` - this is just the minimum quality score required for a site to pass our filtering threshold. Here we set it to 30.
* `--min-meanDP` - the minimum mean depth for a site.
* `--max-meanDP` - the maximum mean depth for a site.
* `--minDP` - the minimum depth allowed for a genotype - any individual failing this threshold is marked as having a missing genotype.
* `--maxDP` - the maximum depth allowed for a genotype - any individual failing this threshold is marked as having a missing genotype.

## Remove multi-clonal infections

Version: bcftools v1.10.2, vcftools v0.1.16, [vcfdo](https://github.com/IDEELResearch/vcfdo).

> The F~WS~ metric estimates the heterozygosity of parasites (HW) within an individual relative to the heterozygosity within a parasite population (HS) using the read count of alleles. F~WS~ metric calculation for each sample was performed using the following equation: F~WS~=1− HW/HS where HW refers to the allele frequency of each unique allele found at specific loci of the parasite sequences within the individual, and HS refers to the corresponding allele frequencies of those unique alleles within the population. F~WS~ ranges from 0 to 1; a low F~WS~ value indicates low inbreeding rates within the parasite population and thus high within-host diversity relative to the population. An F~WS~ threshold ≥ 0.95 indicates samples with clonal (single strain) infections, while samples with an F~WS~ < 0.95 are considered highly likely to come from mixed strain infections, indicating within-host diversity.

Source : [Amegashie et al. (2020)](https://doi.org/10.1186/s12936-020-03510-3).

The F~WS~ must be calculated by population. So we split up the VCF by country. We only calculated F~WS~ for the modern samples.

```{bash}
conda activate vcfdo
while read file_sample
do 
vcftools --gzvcf VivaxSimium_total_snpbi_filtered.ploidy2.vcf.gz --keep ./countries/$file_sample.tsv --recode --stdout | gzip -c > ./vcf_countries/$file_sample.vcf.gz #create the file by country
echo "Sample  Fws Standard_errors nb_sites" > ./fws/fws_$file_sample.txt
vcfdo wsaf -i ./vcf_countries/$file_sample.vcf.gz | vcfdo fws >> ./fws/fws_$file_sample.txt #calculate fws
done < ./list_countries.txt
```

We remove the individuals with a F~WS~ > 0.95 : we keep 432 individuals.

## Remove related samples

Version: bcftools v1.10.2, vcftools v0.1.16, [hmmIBD](https://github.com/glipsnort/hmmIBD), R v4.2.

> Highly related samples and clones can generate spurious signals of population structure, bias estimators of population genetic variation, and violate the assumptions of the model-based population genetic approaches ([Wang 2018](https://doi.org/10.1111/1755-0998.12708)). The relatedness between haploid genotype pairs was measured by estimating the pairwise fraction of the genome identical by descent (*IBD*) between strains within populations.

The IBD must be calculated by countries (only with n>=2).

We used hmmIBD that as a specific format as an input, with only haploid information. For the sites that was heterozygote, they were marked as missing data.

```{bash}
while read country_name
do
vcftools --gzvcf VivaxSimium_total_snpbi_filtered.ploidy2.vcf.gz --keep ./countries/$file_sample.tsv --remove remove_fws_only.txt --recode --stdout | gzip -c > ./vcf_countries/${country_name}.vcf.gz #create the file by country and remove multi-clonal samples

# Transform in hmmIBD format
bcftools annotate -x INFO,^FORMAT/GT ./vcf_countries/${country_name}.vcf.gz | grep -v "##" |cut -d$'\t' -f1-2,10- > temp0_${country_name}

sed 's/0\/0/0/g' temp0_${country_name} > temp1_${country_name}
sed 's/1\/1/1/g' temp1_${country_name} > temp2_${country_name}
sed 's/1\/0/-1/g' temp2_${country_name} > temp3_${country_name}
sed 's/0\/1/-1/g' temp3_${country_name} > temp4_${country_name}
sed 's/0\/1/-1/g' temp4_${country_name} > temp5_${country_name}
sed 's/.\/./-1/g' temp5_${country_name} > temp6_${country_name}
sed 's/PvP01_\([0-9][0-9]*\)_v1/\1/g' temp6_${country_name} > temp7_${country_name} #Change chromosome name to chromosome number
sed 's/vPvP01_\([0-9][0-9]*\)_v1/\1/g' temp7_${country_name} > ./hmm_format/${country_name}_hmm.pf

#Calculate IBD
hmmIBD -i ./hmm_format/${country_name}_hmm.pf -o ./IBD/IBD_${country_name}
done < ./list_countries.txt
```

Isolate pairs that shared >50% of IBD are considered highly related. In each family of related samples, only the strain with the lowest amount of missing data was retained:
```{r}
# Read all IBD files
IBD_all <-
    list.files(path="./Data/IBD/",
               pattern = "*.hmm_fract.txt", 
               full.names = T) %>% 
    map_dfr(~read_table(.), show_col_types=F)

# Add meta-informations
metadata<-read_delim("./Data/metadata_vivaxsimium_fws.csv", 
     delim = "\t", escape_double = FALSE, 
    trim_ws = TRUE, show_col_types = FALSE)
metadata_vivax<-metadata[,c(1,2,9,16)]
colnames(metadata)<-c("sample_ID","species","country","population")
metadata$sample1<-metadata$sample_ID
IBD_all<-inner_join(IBD_all, metadata)

total_list<-unique(c(IBD_all$sample1,IBD_all$sample2)) # List of all the samples
# Only keep pair of individuals with IBD>0.5
fam_IBD<-subset(IBD_all, IBD_all$fract_sites_IBD>0.5)

#Assign family factor by individuals
clst = data.frame(ind = c(as.character(fam_IBD$sample1[1]), as.character(fam_IBD$sample2[1])), grp = c(1,1)) # initialize data.frame
clst
for(i in 2:dim(fam_IBD)[1]){
  if(length(which(as.character(fam_IBD$sample1[i])==clst$ind))>0){
    tmp = data.frame(ind = c(as.character(fam_IBD$sample1[i]), as.character(fam_IBD$sample2[i])), grp = c(clst$grp[which(as.character(fam_IBD$sample1[i])==clst$ind)],clst$grp[which(as.character(fam_IBD$sample1[i])==clst$ind)]))
    clst = rbind(clst, tmp)
  } else if(length(which(as.character(fam_IBD$sample2[i])==clst$ind))>0){
    tmp = data.frame(ind = c(as.character(fam_IBD$sample1[i]), as.character(fam_IBD$sample2[i])), grp = c(clst$grp[which(as.character(fam_IBD$sample2[i])==clst$ind)],clst$grp[which(as.character(fam_IBD$sample2[i])==clst$ind)]))
    clst = rbind(clst, tmp)
  } else {
    tmp = data.frame(ind = c(as.character(fam_IBD$sample1[i]), as.character(fam_IBD$sample2[i])), grp = c(max(clst$grp)+1,max(clst$grp)+1))
    clst = rbind(clst, tmp)
  }
  clst = unique(clst)
}

# import the information of missing data (from vcftools, see above)
ind_miss  <- read_delim("./Data/VivaxSimium_total.ploidy2.imiss", delim = "\t",
                        col_names = c("ind", "ndata", "nfiltered", "nmiss", "fmiss"), skip = 1, show_col_types = FALSE)
data_fam<-inner_join(clst, ind_miss)

### Remove with IBD only
#keep the individual in each family with the less missing data
unrelated<-data_fam %>% 
    group_by(grp) %>% 
    slice(which.min(fmiss))
```

## Create the final dataset filtered

Keep only the samples of the analysis dataset (mono-clonal and not inbred): 429 samples.

```{bash}
vcftools --gzvcf VivaxSimium_total_snpbi_filtered.ploidy2.vcf.gz --remove remove_fws_only.txt --remove remove_IBD_only.txt --recode --stdout | gzip -c > VivaxSimium_filtered_final.ploidy2.vcf.gz
```